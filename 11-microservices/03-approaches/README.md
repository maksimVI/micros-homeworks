# Домашнее задание к занятию «Микросервисы: подходы»

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.

## Ответ 1

Для корпоративного использования выберу **GitLab**, т.к. является популярным (например сервис **Managed Service for GitLab** от YC по умолчанию использует **GitLab CE** [Лицензия, инф. в Docs YC](https://yandex.cloud/ru/docs/managed-gitlab/pricing#license)), есть встроенный инструмент CI/CD (непрерывная интеграция и непрерывная поставка), который не так сложен в настройке и в обслуживании как **Jenkins**. 
**GitLab** - это полноценный веб-инструмент жизненного цикла DevOps с открытым исходным кодом, представляющий систему управления репозиториями кода для Git с собственной вики-системой отслеживания ошибок, CI/CD пайплайном и другими функциями.

Для требований выше предлагаю использовать **GitLab Community Edition (CE)**, т.к. выглядит предпочтительнее из-за возможности самодостаточного развертывания (self-hosted). Мы можем развернуть собственный экземпляр GitLab на серверах любого облачного провайдера (AWS, YC, Google Cloud, Azure). Это дает нам полный контроль над данными и конфигурацией, что критично для крупных компаний. GitLab построен вокруг Git и предоставляет полнофункциональный и производительный сервер для хостинга Git-репозиториев. GitLab позволяет запускать конвейеры вручную через веб-интерфейс с указанием параметров. Для повышенной безопасности GitLab легко интегрируется с внешними хранилищами, такими как **HashiCorp Vault**.

В дальнейшем, параллельно GitLab, можно развивать отдельное решение, например связку **Gitea + Jenkins + огромное кол-во плагинов**, если потребуются решение для специфичной задачи, если компании необходима максимальная гибкость и кастомизация и не пугает высокий уровень сложности. Gitea закроет требования перечисленные выше с 1 по 4, а Jenkins с 4 по 14.

## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.

## Ответ 2

Для организации сбора и анализа логов в микросервисной архитектуре предлагаю использовать стек ELK (ElasticSearch, Logstash, Kibana), т.к. стек ELK обеспечивает полный набор инструментов для сбора, хранения и анализа логов, обеспечивает надежность, масштабируемость и удобство использования.
* Logstash собирает логи с разных источников (файлы, сетевые источники, stdout). Настраивается на прослушивание логов, которые приложения направляют в stdout, тем самым минимизирует требования к самим приложениям (снижает их сложность и уменьшается необходимость изменять код в приложении). Logstash поддерживает сложную буферизацию и возможность повторных попыток при неудачной доставке сообщений в ElasticSearch, т.е. логи будут доставлены даже при каких-то перебоях.
* ElasticSearch - это централизованное хранилище, которое управляет хранением больших объемов логов, обеспечивает быстрый поиск по логам. ElasticSearch масштабируется горизонтально, что позволяет обрабатывать увеличивающиеся объемы данных, характерные для микросервисной архитектуры.
* Kibana - это пользовательский интерфейс для поиска и анализа логов. Упрощает диагностику и устранение проблем. Позволяет сохранять созданные поисковые запросы и дашборды, которыми можно делиться с другими пользователями (разработчиками) организации. 

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.

## Ответ 3

Наиболее подходящим решением для мониторинга динамической микросервисной архитектуры является связка **Prometheus** для сбора и хранения метрик и **Grafana** для их визуализации и анализа.

Это решение состоит из следующих компонентов, которые взаимодействуют между собой:

1. Prometheus - для централизованного хранения и агрегирования метрик.
2. Node Exporter - для сбора метрик состояния ресурсов хостов.
3. cAdvisor - для мониторинга контейнеров и сбора метрик сервисов, работающих в контейнерах.
4. Grafana - для визуализации и настройки пользовательских панелей.

Для сбора метрик со всех хостов, обслуживающих систему будем использовать Node Exporter, который устанавливается на каждый хост. Он будет собирать метрики состояния ресурсов хоста (CPU, RAM, HDD, Network) и отдавать их Prometheus по запросу. cAdvisor будет работать аналогично Node Exporter, только собирать метрики будет по каждому запущенному контейнеру (с запущенным в нем микросервисом) Т.е. Node Exporter работает на уровне всей ОС, не контейнеров. А cAdvisor фокусируется на контейнерах, собирая данные по каждому из них.

Сбор метрик, специфичных для каждого сервиса осуществляется с помощью интеграции клиентских библиотек Prometheus непосредственно в код микросервисов.

Prometheus работает как основной хранилище метрик. Он периодически опрашивает Node Exporter, cAdvisor и другие экспортеры, сохраняя данные в локальной базе данных временных рядов.

Grafana подключается к Prometheus как к источнику данных. С помощью мощного языка запросов (PromQL) Grafana запрашивает у Prometheus необходимые метрики, агрегирует их и отображает в виде графиков, таблиц и дашбордов. Пользователи могут создавать и настраивать собственные дашборды для отслеживания состояния всей системы.

## Задача 4: Логи * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, пишут логи в stdout. 

Добавить в систему сервисы для сбора логов Vector + ElasticSearch + Kibana со всех сервисов, обеспечивающих работу API.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Kibana.
Логин в Kibana должен быть admin, пароль qwerty123456.


## Задача 5: Мониторинг * (необязательная)

Продолжить работу по задаче API Gateway: сервисы, используемые в задаче, предоставляют набор метрик в формате prometheus:

- сервис security по адресу /metrics,
- сервис uploader по адресу /metrics,
- сервис storage (minio) по адресу /minio/v2/metrics/cluster.

Добавить в систему сервисы для сбора метрик (Prometheus и Grafana) со всех сервисов, обеспечивающих работу API.
Построить в Graphana dashboard, показывающий распределение запросов по сервисам.

### Результат выполнения: 

docker compose файл, запустив который можно перейти по адресу http://localhost:8081, по которому доступна Grafana с настроенным Dashboard.
Логин в Grafana должен быть admin, пароль qwerty123456.

---

### Как оформить ДЗ?

Выполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.

---
